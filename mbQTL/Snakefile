#!/usr/bin/env python
import os

# Validate input.
if sum([x is not None for x in [config["inputs"]["genelimit"], config["inputs"]["snplimit"], config["inputs"]["snpgenelimit"]]]) > 1:
    logger.info("Error, selected multiple limitation files. Use genelimit, snplimit, snpgenelimit or none.\n\nExiting.")
    exit("InvalidInput")
if config["general_settings"]["n_genes"] is not None and config["general_settings"]["n_genes"] <= 0:
    logger.info("Error, n_genes needs to be larger than zero.\n\nExiting.")
    exit("InvalidInput")

# Check the input that snakemake cannot check.
if config["inputs"]["repo_dir"] is None:
    logger.info("Error, the repo_dir does not exist.\n\nExiting.")
    exit("MissingRepoDir")
if config["outputs"]["output_dir"] is None:
    logger.info("Error, the output_dir does not exist.\n\nExiting.")
    exit("MissingOutputDir")
if config["inputs"]["genelimit"] is not None and not os.path.exists(config["inputs"]["genelimit"]):
    logger.info("Error, the genelimit file does not exist.\n\nExiting.")
    exit("MissingGeneLimitFile")
if config["inputs"]["snpgenelimit"] is not None and not os.path.exists(config["inputs"]["snpgenelimit"]):
    logger.info("Error, the snpgenelimit file does not exist.\n\nExiting.")
    exit("MissingSNPGeneLimitFile")

# Replace non required variables that are None with empty strings.
for input_variable in ["cov", "genelimit", "snplimit", "snpgenelimit"]:
    if config["inputs"][input_variable] is None:
        config["inputs"][input_variable] = ""

# Add trailing /.
if not config["inputs"]["repo_dir"].endswith("/"):
    config["inputs"]["repo_dir"] += "/"
if not config["outputs"]["output_dir"].endswith("/"):
    config["outputs"]["output_dir"] += "/"

# Set outputall to True if you only test specific variants.
if (config["inputs"]["snpgenelimit"] != "" or config["inputs"]["snplimit"] != "") and config["general_settings"]["use_snpannotation"]:
    logger.info("Warning, setting use_snpannotation to False since snpgenelimit / snplimit is used.")
    config["general_settings"]["use_snpannotation"] = False
if config["inputs"]["snpgenelimit"] == "" and config["inputs"]["snplimit"] == "" and config["general_settings"]["filter_vcf"]:
    logger.info("Warning, setting filter_vcf to False since snpgenelimit / snplimit is not used.")
    config["general_settings"]["filter_vcf"] = False
if config["inputs"]["snpgenelimit"] != "" and not config["qtl_settings"]["outputall"]:
    logger.info("Warning, setting outputall to True since snpgenelimit is used.")
    config["qtl_settings"]["outputall"] = True
if config["inputs"]["snpgenelimit"] != "" and not config["qtl_settings"]["perm"] == 0:
    logger.info("Warning, setting perm to 0 since snpgenelimit is used.")
    config["qtl_settings"]["perm"] = 0

# Some friendly reminders.
if config["general_settings"]["n_genes"] is None and config["run_qtl_time"] == 0:
    logger.info("Warning, you are running all tests in one job file but the runtime for this "
                "job is max {}. If you tink this is too short you should increase"
                "run_qtl_time to 1 or higher.".format(config["cluster_time"][config["run_qtl_time"]]))
if config["general_settings"]["n_genes"] is not None and config["run_qtl_time"] != 0:
    logger.info("Warning, you are running tests in multiple job files but the runtime for each "
                "job is max {}. If you tink this is too long you should decrease"
                "run_qtl_time to e.g. 0.".format(config["cluster_time"][config["run_qtl_time"]]))

# Define the expected input files.
covariates = ["default"]
if config["inputs"]["cov"] != "" and config["general_settings"]["n_pcs"] is None:
    covariates = ["cov"]
elif config["general_settings"]["n_pcs"] is not None:
    prefix = ""
    if config["inputs"]["cov"] != "":
        prefix = "cov"

    covariates = []
    if not isinstance(config["general_settings"]["n_pcs"], list):
        config["general_settings"]["n_pcs"] = [config["general_settings"]["n_pcs"]]
    for n_pcs in config["general_settings"]["n_pcs"]:
        covariates.append(prefix + str(n_pcs) + "Pcs")


wildcard_constraints:
    n_pcs = "[0-9]+"


rule all:
    input:
        top_hits = expand(config["outputs"]["output_dir"] + "output/{cov}/" + config["outputs"]["output_prefix"] + "-TopEffectsWithqval.txt", cov=covariates),
        results = config["outputs"]["output_dir"] + "output/" + config["outputs"]["output_prefix"] + "-results.txt"


rule create_gene_annotation:
    input:
        gtf = config["inputs"]["annotation"]
    output:
        dupl_annotation = temp(config["outputs"]["output_dir"] + "create_annotation/refdata-gex-GeneAnnotation.WithDuplicates.txt.gz"),
        annotation = config["outputs"]["output_dir"] + "create_annotation/refdata-gex-GeneAnnotation.txt.gz"
    resources:
        mem_per_thread_gb = lambda wildcards, attempt: attempt * config["create_gene_annotation_memory"],
        disk_per_thread_gb = lambda wildcards, attempt: attempt * config["create_gene_annotation_memory"],
        time = lambda wildcards,attempt: config["cluster_time"][(attempt - 1) + config["create_gene_annotation_time"]]
    threads: config["create_gene_annotation_threads"]
    params:
        bind = config["inputs"]["bind_path"],
        sif = config["inputs"]["singularity_image"],
        script = config["inputs"]["repo_dir"] + "scripts/create_annotation_file.py",
        feature_name = config["create_annotation_settings"]["feature_name"],
        autosomes_only = "--autosomes_only " if config["create_annotation_settings"]["autosomes_only"] else "",
        out = config["outputs"]["output_dir"] + "create_annotation/"
    log: config["outputs"]["output_dir"] + "log/create_gene_annotation.log"
    shell:
        """
        singularity exec --bind {params.bind} {params.sif} python {params.script} \
            --in_gtf {input.gtf} \
            --feature_name {params.feature_name} \
            {params.autosomes_only} \
            --out_dir {params.out} > {log} 2>&1
        """


rule create_snp_annotation:
    input:
        vcf = config["inputs"]["vcf"]
    output:
        annotation = config["outputs"]["output_dir"] + "create_annotation/snp_annotation.txt.gz"
    resources:
        mem_per_thread_gb = lambda wildcards, attempt: attempt * config["create_snp_annotation_memory"],
        disk_per_thread_gb = lambda wildcards, attempt: attempt * config["create_snp_annotation_memory"],
        time = lambda wildcards,attempt: config["cluster_time"][(attempt - 1) + config["create_snp_annotation_time"]]
    threads: config["create_snp_annotation_threads"]
    params:
        bind = config["inputs"]["bind_path"],
        sif = config["inputs"]["singularity_image"],
    log: config["outputs"]["output_dir"] + "log/create_snp_annotation.log"
    shell:
        """
        singularity exec --bind {params.bind} {params.sif} zcat {input.vcf} | grep "^[^#;]" | awk -v OFS='\t' '{{print $3,$1,$2}}' | gzip -c > {output.annotation}
        """


rule smf_to_gte:
    input:
        smf = config["inputs"]["gte"],
    output:
        gte = config["outputs"]["output_dir"] + "smf_to_gte/gte.txt"
    resources:
        mem_per_thread_gb = lambda wildcards, attempt: attempt * config["smf_to_gte_memory"],
        disk_per_thread_gb = lambda wildcards, attempt: attempt * config["smf_to_gte_memory"],
        time = lambda wildcards,attempt: config["cluster_time"][(attempt - 1) + config["smf_to_gte_time"]]
    threads: config["smf_to_gte_threads"]
    params:
        bind = config["inputs"]["bind_path"],
        sif = config["inputs"]["singularity_image"],
    log: config["outputs"]["output_dir"] + "log/smf_to_gte.log"
    shell:
        """
        singularity exec --bind {params.bind} {params.sif} awk 'BEGIN{{ FS = OFS = "\\t" }} {{ print $1, $2, "Dataset" }}' {input.smf} > {output.gte}
        """


rule snpgenelimit_to_vars:
    input:
        sgl = config["inputs"]["snpgenelimit"]
    output:
        vars = temp(config["outputs"]["output_dir"] + "genotype/variants.txt")
    resources:
        mem_per_thread_gb = lambda wildcards, attempt: attempt * config["snpgenelimit_to_vars_memory"],
        disk_per_thread_gb = lambda wildcards, attempt: attempt * config["snpgenelimit_to_vars_memory"],
        time = lambda wildcards,attempt: config["cluster_time"][(attempt - 1) + config["snpgenelimit_to_vars_time"]]
    threads: config["snpgenelimit_to_vars_threads"]
    params:
        bind = config["inputs"]["bind_path"],
        sif = config["inputs"]["singularity_image"],
        cat = "zcat" if config["inputs"]["snpgenelimit"].endswith(".gz") else "cat",
    log: config["outputs"]["output_dir"] + "log/snpgenelimit_to_vars.log"
    shell:
        """
        singularity exec --bind {params.bind} {params.sif} {params.cat} {input.sgl} | awk 'BEGIN{{ FS = OFS = "\\t" }} {{ print $1 }}' > {output.vars}
        """


rule index_vcf:
    input:
        vcf = config["inputs"]["vcf"]
    output:
        index = config["inputs"]["vcf"] + ".tbi"
    resources:
        mem_per_thread_gb = lambda wildcards, attempt: attempt * config["index_vcf_memory"],
        disk_per_thread_gb = lambda wildcards, attempt: attempt * config["index_vcf_memory"],
        time = lambda wildcards, attempt: config["cluster_time"][(attempt - 1) + config["index_vcf_time"]]
    threads: config["index_vcf_threads"]
    params:
        bind = config["inputs"]["bind_path"],
        sif = config["inputs"]["singularity_image"],
    log: config["outputs"]["output_dir"] + "log/index_vcf.log"
    shell:
        """
        singularity exec --bind {params.bind} {params.sif} tabix -p vcf {input.vcf}
        """


def get_gte(wildcards):
    if config["inputs"]["gte"].endswith(".smf"):
        return config["outputs"]["output_dir"] + "smf_to_gte/gte.txt"
    return config["inputs"]["gte"]

def get_variants(wildcards):
    if config["inputs"]["snplimit"] == "" and config["inputs"]["snpgenelimit"] != "":
        return config["outputs"]["output_dir"] + "genotype/variants.txt"
    elif config["inputs"]["snplimit"] != "" and config["inputs"]["snpgenelimit"] == "":
        return config["inputs"]["snplimit"]
    else:
        print("Error in get_variants")
        exit()


def get_basename(fpath):
    return os.path.basename(fpath).rstrip(".gz").rstrip(".txt").rstrip(".tsv").rstrip(".csv").rstrip(".vcf")


rule filter_vcf:
    input:
        vcf = config["inputs"]["vcf"],
        sgl = config["inputs"]["snpgenelimit"],
        gte = get_gte,
        vars = get_variants
    output:
        samples = temp(config["outputs"]["output_dir"] + "genotype/samples.txt"),
        vcf_gz = temp(config["outputs"]["output_dir"] + "genotype/" + get_basename(config["inputs"]["vcf"]) + "_" + get_basename(config["inputs"]["snpgenelimit"]) + ".vcf.gz"),
        vcf_bgz = config["outputs"]["output_dir"] + "genotype/" + get_basename(config["inputs"]["vcf"]) + "_" + get_basename(config["inputs"]["snpgenelimit"]) + ".vcf.bgz",
        index = config["outputs"]["output_dir"] + "genotype/" + get_basename(config["inputs"]["vcf"]) + "_" + get_basename(config["inputs"]["snpgenelimit"]) + ".vcf.bgz.tbi"
    resources:
        mem_per_thread_gb = lambda wildcards, attempt: attempt * config["filter_vcf_memory"],
        disk_per_thread_gb = lambda wildcards, attempt: attempt * config["filter_vcf_memory"],
        time = lambda wildcards,attempt: config["cluster_time"][(attempt - 1) + config["filter_vcf_time"]]
    threads: config["filter_vcf_threads"]
    params:
        bind = config["inputs"]["bind_path"],
        sif = config["inputs"]["singularity_image"],
        script = config["inputs"]["repo_dir"] + "scripts/filter_vcf.py"
    log: config["outputs"]["output_dir"] + "log/filter_vcf.log"
    shell:
        """
        singularity exec --bind {params.bind} {params.sif} awk 'BEGIN{{ FS = OFS = "\\t" }} {{ print $1 }}' {input.gte} > {output.samples}
        singularity exec --bind {params.bind} {params.sif} python {params.script} \
            --vcf {input.vcf} \
            --variants {input.vars} \
            --samples {output.samples} \
            --outfile {output.vcf_gz} > {log} 2>&1
            
        if [[ "$(singularity exec --bind {params.bind} {params.sif} zcat {output.vcf_gz} | wc -l)" -le "1" ]]; 
        then
           echo "Error, no results in {output.vcf_gz}"
           rm {output.vcf_gz}
        fi
            
        singularity exec --bind {params.bind} {params.sif} gunzip -c {output.vcf_gz} | \
            singularity exec --bind {params.bind} {params.sif} bgzip > {output.vcf_bgz}
        singularity exec --bind {params.bind} {params.sif} tabix -p vcf {output.vcf_bgz}
        """


rule pca:
    input:
        data = config["inputs"]["exp"],
        gte = get_gte
    output:
        pca = config["outputs"]["output_dir"] + "pca/" + get_basename(config["inputs"]["exp"]) + "Pcs.txt.gz",
        rot = config["outputs"]["output_dir"] + "pca/" + get_basename(config["inputs"]["exp"]) + "Pcs_rot.txt.gz",
        var = config["outputs"]["output_dir"] + "pca/" + get_basename(config["inputs"]["exp"]) + "Pcs_var.txt.gz"
    resources:
        mem_per_thread_gb = lambda wildcards, attempt: attempt * config["pca_memory"],
        disk_per_thread_gb = lambda wildcards, attempt: attempt * config["pca_memory"],
        time = lambda wildcards,attempt: config["cluster_time"][(attempt - 1) + config["pca_time"]]
    threads: config["pca_threads"]
    params:
        bind = config["inputs"]["bind_path"],
        sif = config["inputs"]["singularity_image"],
        script = config["inputs"]["repo_dir"] + "scripts/pca.py",
        out = config["outputs"]["output_dir"] + "pca/" + get_basename(config["inputs"]["exp"])
    log: config["outputs"]["output_dir"] + "log/pca.log"
    shell:
        """
        singularity exec --bind {params.bind} {params.sif} python {params.script} \
            --data {input.data} \
            --gte {input.gte} \
            --transpose \
            --scale \
            --out {params.out} > {log} 2>&1
        """


rule filter_matrix:
    input:
        data = config["outputs"]["output_dir"] + "pca/" + get_basename(config["inputs"]["exp"]) + "Pcs.txt.gz"
    output:
        out = config["outputs"]["output_dir"] + "pca/" + get_basename(config["inputs"]["exp"]) + "{n_pcs}Pcs.txt.gz"
    resources:
        mem_per_thread_gb = lambda wildcards, attempt: attempt * config["filter_matrix_memory"],
        disk_per_thread_gb = lambda wildcards, attempt: attempt * config["filter_matrix_memory"],
        time = lambda wildcards,attempt: config["cluster_time"][(attempt - 1) + config["filter_matrix_time"]]
    threads: config["filter_matrix_threads"]
    params:
        bind = config["inputs"]["bind_path"],
        sif = config["inputs"]["singularity_image"],
        script = config["inputs"]["repo_dir"] + "scripts/filter_matrix.py",
    log: config["outputs"]["output_dir"] + "log/filter_matrix.{n_pcs}Pcs.log"
    shell:
        """
        singularity exec --bind {params.bind} {params.sif} python {params.script} \
            --data {input.data} \
            --head {wildcards.n_pcs} \
            --outfile {output.out} > {log} 2>&1
        """


rule concat_covs:
    input:
        cov = config["inputs"]["cov"],
        pca = config["outputs"]["output_dir"] + "pca/" + get_basename(config["inputs"]["exp"]) + "{n_pcs}Pcs.txt.gz"
    output:
        cov = config["outputs"]["output_dir"] + "cov/" + get_basename(config["inputs"]["exp"]) + "cov{n_pcs}Pcs.txt.gz"
    resources:
        mem_per_thread_gb = lambda wildcards, attempt: attempt * config["concat_covs_memory"],
        disk_per_thread_gb = lambda wildcards, attempt: attempt * config["concat_covs_memory"],
        time = lambda wildcards,attempt: config["cluster_time"][(attempt - 1) + config["concat_covs_time"]]
    threads: config["concat_covs_threads"]
    params:
        bind = config["inputs"]["bind_path"],
        sif = config["inputs"]["singularity_image"],
        script = config["inputs"]["repo_dir"] + "scripts/merge_covs.py",
        out = lambda wildcards: config["outputs"]["output_dir"] + "cov/" + get_basename(config["inputs"]["exp"]) + "cov" + wildcards.n_pcs + "Pcs"
    log: config["outputs"]["output_dir"] + "log/concat_covs.cov{n_pcs}Pcs.log"
    shell:
        """
        singularity exec --bind {params.bind} {params.sif} python {params.script} \
            --covs {input.cov} {input.pca} \
            --out {params.out} > {log} 2>&1
        """


def get_cov(wildcards):
    if wildcards.cov == "cov" or wildcards.cov == "cov0Pcs":
        return config["inputs"]["cov"]
    elif not wildcards.cov.startswith("cov") and wildcards.cov.endswith("Pcs"):
        return config["outputs"]["output_dir"] + "pca/" + get_basename(config["inputs"]["exp"]) + "{cov}.txt.gz"
    return config["outputs"]["output_dir"] + "cov/" + get_basename(config["inputs"]["exp"]) + "{cov}.txt.gz"



rule regressor:
    input:
        data = config["inputs"]["exp"],
        cov = get_cov
    output:
        data = config["outputs"]["output_dir"] + "regressor/" + get_basename(config["inputs"]["exp"]) + ".{cov}.CovariatesRemovedOLS.txt.gz"
    resources:
        mem_per_thread_gb = lambda wildcards, attempt: attempt * config["regressor_memory"],
        disk_per_thread_gb = lambda wildcards, attempt: attempt * config["regressor_memory"],
        time = lambda wildcards,attempt: config["cluster_time"][(attempt - 1) + config["regressor_time"]]
    threads: config["regressor_threads"]
    params:
        bind = config["inputs"]["bind_path"],
        sif = config["inputs"]["singularity_image"],
        script = config["inputs"]["repo_dir"] + "scripts/regressor.py",
        out = config["outputs"]["output_dir"] + "regressor/" + get_basename(config["inputs"]["exp"]) + ".{cov}"
    log: config["outputs"]["output_dir"] + "log/regressor.{cov}.log"
    shell:
        """
        singularity exec --bind {params.bind} {params.sif} python {params.script} \
            --data {input.data} \
            --cov {input.cov} \
            --out {params.out} > {log} 2>&1
        """



def get_exp(wildcards):
    if wildcards.cov == "default" or wildcards.cov == "0Pcs":
        return config["inputs"]["exp"]
    return config["outputs"]["output_dir"] + "regressor/" + get_basename(config["inputs"]["exp"]) + ".{cov}.CovariatesRemovedOLS.txt.gz"



# TODO: perhaps better to use the genelimit / snpgenelimit file here if it is given so the jobs are more
#   equally distributed.
checkpoint create_batches:
    input:
        exp = get_exp
    output:
        batches = directory(config["outputs"]["output_dir"] + "batches/{cov}/")
    resources:
        mem_per_thread_gb = lambda wildcards, attempt: attempt * config["regressor_memory"],
        disk_per_thread_gb = lambda wildcards, attempt: attempt * config["regressor_memory"],
        time = lambda wildcards,attempt: config["cluster_time"][(attempt - 1) + config["regressor_time"]]
    threads: config["regressor_threads"]
    params:
        bind = config["inputs"]["bind_path"],
        sif = config["inputs"]["singularity_image"],
        script = config["inputs"]["repo_dir"] + "scripts/create_batches.py",
        n_genes = config["general_settings"]["n_genes"],
        out = config["outputs"]["output_dir"] + "batches/{cov}/" + config["outputs"]["output_prefix"]
    log: config["outputs"]["output_dir"] + "log/create_batches.{cov}.log"
    shell:
        """
        mkdir -p {output.batches}
        singularity exec --bind {params.bind} {params.sif} python {params.script} \
            --exp {input.exp} \
            --n_genes {params.n_genes} \
            --out {params.out} > {log} 2>&1
        """


def get_annotation(wildcards):
    if config["inputs"]["annotation"].endswith(".gtf"):
        return config["outputs"]["output_dir"] + "create_annotation/refdata-gex-GeneAnnotation.txt.gz"
    return config["inputs"]["annotation"]

def get_snpannotation(wildcards):
    if config["general_settings"]["use_snpannotation"]:
        return config["outputs"]["output_dir"] + "create_annotation/snp_annotation.txt.gz"
    return []


def get_vcf(wildcards):
    if config["inputs"]["snpgenelimit"] != "" and config["general_settings"]["filter_vcf"]:
        return config["outputs"]["output_dir"] + "genotype/" + get_basename(config["inputs"]["vcf"]) + "_" + get_basename(config["inputs"]["snpgenelimit"]) + ".vcf.bgz"
    return config["inputs"]["vcf"]


def get_vcf_index(wildcards):
    return get_vcf(wildcards) + ".tbi"


def get_genelimit(wildcards):
    prefix = "--genelimit "
    if config["inputs"]["genelimit"] != "":
        return prefix + config["inputs"]["genelimit"]
    elif config["general_settings"]["n_genes"] is not None:
        return prefix + config["outputs"]["output_dir"] + "batches/" + wildcards.cov + "/" + wildcards.batch + "-genes.txt"

    return ""

def get_snplimit(wildcards):
    prefix = "--snplimit "
    if config["inputs"]["snplimit"] != "":
        return prefix + config["inputs"]["snplimit"]

    return ""

def get_snpgenelimit(wildcards):
    prefix = "--snpgenelimit "
    if config["inputs"]["snpgenelimit"] != "":
        return prefix + config["inputs"]["snpgenelimit"]

    return ""


rule run_qtl:
    input:
        annotation = get_annotation,
        snpannotation = get_snpannotation,
        vcf = get_vcf,
        index = get_vcf_index,
        exp = get_exp,
        gte = get_gte
    output:
        log = config["outputs"]["output_dir"] + "output/{cov}/{batch}-log.txt.gz",
        top = config["outputs"]["output_dir"] + "output/{cov}/{batch}-TopEffects.txt",
        all = config["outputs"]["output_dir"] + "output/{cov}/{batch}-AllEffects.txt.gz" if config["qtl_settings"]["outputall"] else [],
        finished = config["outputs"]["output_dir"] + "output/{cov}/{batch}-TopEffects.finished"
    resources:
        java_mem_gb = lambda wildcards, attempt: attempt * config["run_qtl_memory"] * config["run_qtl_threads"] - config["settings_extra"]["java_memory_buffer"],
        mem_per_thread_gb = lambda wildcards, attempt: attempt * config["run_qtl_memory"],
        disk_per_thread_gb = lambda wildcards, attempt: attempt * config["run_qtl_memory"],
        time = lambda wildcards, attempt: config["cluster_time"][(attempt - 1) + config["run_qtl_time"]]
    threads: config["run_qtl_threads"]
    params:
        bind = config["inputs"]["bind_path"],
        sif = config["inputs"]["singularity_image"],
        jar = config["inputs"]["mbqtl_jar"],
        java_threads = config["run_qtl_threads"] * 2,
        snpannotation = lambda wildcards: "--snpannotation " + get_snpannotation(wildcards) if config["general_settings"]["use_snpannotation"] else "",
        perm = config["qtl_settings"]["perm"],
        genelimit = get_genelimit,
        snplimit = get_snplimit,
        snpgenelimit = get_snpgenelimit,
        ciswindow = config["qtl_settings"]["ciswindow"],
        maf = config["qtl_settings"]["maf"],
        cr = config["qtl_settings"]["cr"],
        hwep = config["qtl_settings"]["hwep"],
        minobservations = config["qtl_settings"]["minobservations"],
        mingenotypecount = config["qtl_settings"]["mingenotypecount"],
        replacemissinggenotypes = "--replacemissinggenotypes" if config["qtl_settings"]["replacemissinggenotypes"] else "",
        norank = "--norank" if config["qtl_settings"]["norank"] else "",
        fisherzmeta = "--fisherzmeta" if config["qtl_settings"]["fisherzmeta"] else "",
        outputall = "--outputall" if config["qtl_settings"]["outputall"] else "",
        out = lambda wildcards: config["outputs"]["output_dir"] + "output/" + wildcards.cov + "/" + wildcards.batch
    log: config["outputs"]["output_dir"] + "log/run_qtl.{cov}.{batch}.log"
    shell:
        """
        singularity exec --bind {params.bind} {params.sif} java -Xmx{resources.java_mem_gb}g -Xms{resources.java_mem_gb}g \
            -Djava.util.concurrent.ForkJoinPool.common.parallelism={params.java_threads} \
            -Dmaximum.threads={params.java_threads} -Dthread.pool.size={params.java_threads} \
            -jar {params.jar} \
            --mode mbqtl \
            --vcf {input.vcf} \
            --exp {input.exp} \
            --gte {input.gte} \
            --annotation {input.annotation} \
            {params.snpannotation} \
            {params.genelimit} \
            {params.snpgenelimit} \
            --perm {params.perm} \
            --ciswindow {params.ciswindow} \
            --maf {params.maf} \
            --cr {params.cr} \
            --hwep {params.hwep} \
            --minobservations {params.minobservations} \
            --mingenotypecount {params.mingenotypecount} \
            {params.replacemissinggenotypes} \
            {params.norank} \
            {params.fisherzmeta} \
            {params.outputall} \
            --out {params.out} > {log} 2>&1
            
        if [[ "$(singularity exec --bind {params.bind} {params.sif} cat {output.top} | wc -l)" -le "1" ]]; 
        then
           echo "Error, no results in {output.top}"
           rm {output.top}
        fi
        """


def get_batches(wildcards):
    out_dir = checkpoints.create_batches.get(**wildcards).output[0]
    batches = glob_wildcards(os.path.join(out_dir, "{batch}-genes.txt"))
    return batches.batch


rule merge:
    input:
        top = lambda wildcards: expand(config["outputs"]["output_dir"] + "output/{cov}/" + "{batch}-TopEffects.txt", batch=get_batches(wildcards), allow_missing=True)
    output:
        top = config["outputs"]["output_dir"] + "output/{cov}/" + config["outputs"]["output_prefix"] + "-merged.txt"
    resources:
        mem_per_thread_gb = lambda wildcards, attempt: attempt * config["merge_memory"],
        disk_per_thread_gb = lambda wildcards, attempt: attempt * config["merge_memory"],
        time = lambda wildcards,attempt: config["cluster_time"][(attempt - 1) + config["merge_time"]]
    threads: config["merge_threads"]
    params:
        bind = config["inputs"]["bind_path"],
        sif = config["inputs"]["singularity_image"],
        script = config["inputs"]["repo_dir"] + "scripts/merge.py",
        input_dir = config["outputs"]["output_dir"] + "output/{cov}/" + config["outputs"]["output_prefix"],
        out = config["outputs"]["output_dir"] + "output/{cov}/" + config["outputs"]["output_prefix"] + "-merged"
    log: config["outputs"]["output_dir"] + "log/merge.{cov}.log"
    shell:
        """
        singularity exec --bind {params.bind} {params.sif} python {params.script} \
            --input_dir {params.input_dir} \
            --out {params.out} > {log} 2>&1
        """

def get_top_hits(wildcards):
    if config["general_settings"]["n_genes"] is None:
        return config["outputs"]["output_dir"] + "output/{cov}/" + config["outputs"]["output_prefix"] + "-TopEffects.txt"

    return config["outputs"]["output_dir"] + "output/{cov}/" + config["outputs"]["output_prefix"] + "-merged.txt"


rule qvalues:
    input:
        top_hits = get_top_hits
    output:
        top_hits = config["outputs"]["output_dir"] + "output/{cov}/" + config["outputs"]["output_prefix"] + "-TopEffectsWithqval.txt",
        empty = temp(config["outputs"]["output_dir"] + "figures/{cov}/Rplots.pdf"),
        fig1 = config["outputs"]["output_dir"] + "figures/{cov}/" + config["outputs"]["output_prefix"] + "_overview.png",
        fig2 = config["outputs"]["output_dir"] + "figures/{cov}/" + config["outputs"]["output_prefix"] + "_hist.png"
    resources:
        mem_per_thread_gb = lambda wildcards, attempt: attempt * config["qvalues_memory"],
        disk_per_thread_gb = lambda wildcards, attempt: attempt * config["qvalues_memory"],
        time = lambda wildcards,attempt: config["cluster_time"][(attempt - 1) + config["qvalues_time"]]
    threads: config["qvalues_threads"]
    params:
        bind = config["inputs"]["bind_path"],
        sif = config["inputs"]["singularity_image"],
        script = config["inputs"]["repo_dir"] + "scripts/multiple_testing_correction.R",
        beta_dist_a = "BetaDistAlpha",
        beta_dist_b = "BetaDistBeta",
        nom_threshold = "PvalueNominalThreshold",
        pvalue = "BetaAdjustedMetaP" if config["qtl_settings"]["perm"] > 0 else "MetaP",
        qvalue = "qval",
        alpha = 0.05,
        data_out = config["outputs"]["output_dir"] + "output/{cov}/" + config["outputs"]["output_prefix"] + "-TopEffects",
        plot_out = config["outputs"]["output_dir"] + "figures/{cov}/" + config["outputs"]["output_prefix"],
        suffix = "Withqval"
    log: config["outputs"]["output_dir"] + "log/qvalues.{cov}.log"
    shell:
        """
         singularity exec --bind {params.bind} {params.sif} Rscript {params.script} \
            --input {input.top_hits} \
            --beta_dist_a {params.beta_dist_a} \
            --beta_dist_b {params.beta_dist_b} \
            --nom_threshold {params.nom_threshold} \
            --pvalue {params.pvalue} \
            --qvalue {params.qvalue} \
            --alpha {params.alpha} \
            --data_out {params.data_out} \
            --plot_out {params.plot_out} \
            --suffix {params.suffix} > {log} 2>&1
        """


rule results:
    input:
        data = expand(config["outputs"]["output_dir"] + "output/{cov}/" + config["outputs"]["output_prefix"] + "-TopEffectsWithqval.txt", cov=covariates)
    output:
        out = config["outputs"]["output_dir"] + "output/" + config["outputs"]["output_prefix"] + "-results.txt"
    resources:
        mem_per_thread_gb = lambda wildcards, attempt: attempt * config["results_memory"],
        disk_per_thread_gb = lambda wildcards, attempt: attempt * config["results_memory"],
        time = lambda wildcards,attempt: config["cluster_time"][(attempt - 1) + config["results_time"]]
    threads: config["results_threads"]
    params:
        bind = config["inputs"]["bind_path"],
        sif = config["inputs"]["singularity_image"],
        script = config["inputs"]["repo_dir"] + "scripts/results.py",
        data = config["outputs"]["output_dir"] + "output/*/" + config["outputs"]["output_prefix"] + "-TopEffectsWithqval.txt",
        nom_pvalue_column = "MetaP",
        perm_pvalue_column = "BetaAdjustedMetaP",
        qvalue_column = "qval",
        minimimal_reporting_p = 0.05
    log: config["outputs"]["output_dir"] + "log/results.log"
    shell:
        """
        singularity exec --bind {params.bind} {params.sif} python {params.script} \
            --data '{params.data}' \
            --nom_pvalue_column {params.nom_pvalue_column} \
            --perm_pvalue_column {params.perm_pvalue_column} \
            --qvalue_column {params.qvalue_column} \
            --minimimal_reporting_p {params.minimimal_reporting_p} \
            --out {output.out} > {log} 2>&1
        """

